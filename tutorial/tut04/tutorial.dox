//! \page tutorial04 Tutorial 4: Reference solutions
//! \htmlonly
<div id='TOC'></div>
\endhtmlonly
//! 
//! 
//! \section intro Introduction
//! 
//! This tutorial demonstrates how to make reference solutions on the CPU to
//! compare the GPU results.
//! 
//! @section code Code
//! 
//! \code
//! #include "agile/gpu_environment.hpp"
//! #include "agile/gpu_vector.hpp"
//! #include "agile/gpu_matrix.hpp"
//! 
//! #include <iostream>
//! #include <iomanip>
//! 
//! \endcode
//!  Include the header for vector operations on the CPU.
//! \code
//! #include "agile/cpu_vector.hpp"
//! \endcode
//!  There is also a header implementing a dense matrix on the CPU.
//! \code
//! #include "agile/cpu_matrix.hpp"
//! 
//! \endcode
//!  Again our vector output function.
//! \code
//! void output(const char* string, const std::vector<float>& x)
//! {
//!   std::cout << string;
//!   for (unsigned counter = 0; counter < x.size(); ++counter)
//!     std::cout << x[counter] << " ";
//!   std::cout << std::endl;
//! }
//! 
//! \endcode
//!  The function to print a matrix.
//! \code
//! void output(const char* string, unsigned num_rows, unsigned num_columns,
//!             std::vector<float> data)
//! {
//!   std::vector<float>::iterator iter = data.begin();
//!   std::cout << string << std::endl;
//!   for (unsigned row = 0; row < num_rows; ++row)
//!   {
//!     std::cout << "  ";
//!     for (unsigned column = 0; column < num_columns; ++column)
//!       std::cout << std::setw(4) << *iter++;
//!     std::cout << std::endl;
//!   }
//!   std::cout << std::endl;
//! }
//! 
//! int main()
//! {
//! \endcode
//!  The initialization is the same as always.
//! \code
//!   agile::GPUEnvironment::allocateGPU(0);
//!   agile::GPUEnvironment::printInformation(std::cout);
//!   std::cout << std::endl;
//! 
//! \endcode
//!  We create two vectors on the host an output them.
//! \code
//!   std::vector<float> x_host, y_host;
//!   for (unsigned counter = 0; counter < 10; ++counter)
//!   {
//!     x_host.push_back(counter * 2 + 1);
//!     y_host.push_back(counter * 2 + 2);
//!   }
//!   output("x: ", x_host);
//!   output("y: ", y_host);
//! 
//! \endcode
//!  Transfer the vectors to the GPU.
//! \code
//!   agile::GPUVector<float> x, y;
//!   x.assignFromHost(x_host.begin(), x_host.end());
//!   y.assignFromHost(y_host.begin(), y_host.end());
//! 
//! \endcode
//!  As an example we perform the summation \f$ z \leftarrow x + y \f$.
//! \code
//!   agile::GPUVector<float> z(x.size());
//!   agile::addVector(x, y, z);
//! 
//! \endcode
//!  Print this result.
//! \code
//!   std::vector<float> z_host;
//!   z.copyToHost(z_host);
//!   output("GPU - x + y: ", z_host);
//! 
//! \endcode
//!  How do we know that the GPU implementation is correct? Well, simply do
//!  the same computation on the CPU.
//! \code
//!   std::vector<float> z_reference(x_host.size());
//!   agile::addVector(x_host, y_host, z_reference);
//!   output("CPU - x + y: ", z_reference);
//! 
//! \endcode
//!  Et voila... The results are identical. The header \p cpu_vector.hpp
//!  provides all the functionality of \p gpu_vector.hpp for the CPU.
//!  Have a look at the scalar product.
//! \code
//!   std::cout << "GPU - (x, y) = " << agile::getScalarProduct(x, y)
//!             << std::endl;
//!   std::cout << "CPU - (x, y) = " << agile::getScalarProduct(x_host, y_host)
//!             << std::endl;
//! 
//! \endcode
//!  Now, we perform some test with a GPU matrix.
//!  First, create a matrix and print it:
//! \code
//!   std::vector<float> matrix_data;
//!   for (unsigned row = 0; row < x.size(); ++row)
//!     for (unsigned column = 0; column < x.size(); ++column)
//!       matrix_data.push_back(float(row + 1) * float(2 * column + 1));
//!   output("A: ", x.size(), x.size(), matrix_data);
//! 
//! \endcode
//!  Transfer the matrix to the GPU and perform a multiplication with \p x.
//! \code
//!   agile::GPUMatrix<float> A(x.size(), x.size(), &matrix_data[0]);
//!   agile::multiply(A, x, z);
//!   z.copyToHost(z_host);
//!   output("GPU - A * x: ", z_host);
//! 
//! \endcode
//!  Do a reference calculation on the CPU.
//! \code
//!   agile::CPUMatrix<float> A_host(x_host.size(), x_host.size(), &matrix_data[0]);
//!   agile::multiply(A_host, x_host, z_reference);
//!   output("CPU - A * x: ", z_reference);
//! 
//! \endcode
//!  The transposed product should also bring the same result.
//! \code
//!   agile::multiply(x, A, z);
//!   z.copyToHost(z_host);
//!   output("GPU - A^H * x: ", z_host);
//!   agile::multiply(x_host, A_host, z_reference);
//!   output("CPU - A^H * x: ", z_reference);
//! 
//! \endcode
//!  This tutorial demonstrated how to make reference solutions on the CPU.
//! \code
//!   return 0;
//! }
//! 
//! \endcode
//! 
//! \section result Result
//! 
//! The output of the program will look like the one below.
//! 
//! <code>
//! Device name:                  GeForce 9600 GT<BR>
//! Compute capability:           1.1<BR>
//! Clock frequency (MHz):        1600<BR>
//! 32-bit registers per block:   8192<BR>
//! Total global memory (MB):     511<BR>
//! Shared memory per block (kB): 16<BR>
//! Total const memory (kB):      64<BR>
//! Number of multiprocessors:    8<BR>
//! Max threads per block:        512<BR>
//! <BR>
//! x: 1 3 5 7 9 11 13 15 17 19<BR>
//! y: 2 4 6 8 10 12 14 16 18 20<BR>
//! GPU - x + y: 3 7 11 15 19 23 27 31 35 39<BR>
//! CPU - x + y: 3 7 11 15 19 23 27 31 35 39<BR>
//! GPU - (x, y) = 1430<BR>
//! CPU - (x, y) = 1430<BR>
//! A:<BR>
//!      1   3   5   7   9  11  13  15  17  19<BR>
//!      2   6  10  14  18  22  26  30  34  38<BR>
//!      3   9  15  21  27  33  39  45  51  57<BR>
//!      4  12  20  28  36  44  52  60  68  76<BR>
//!      5  15  25  35  45  55  65  75  85  95<BR>
//!      6  18  30  42  54  66  78  90 102 114<BR>
//!      7  21  35  49  63  77  91 105 119 133<BR>
//!      8  24  40  56  72  88 104 120 136 152<BR>
//!      9  27  45  63  81  99 117 135 153 171<BR>
//!     10  30  50  70  90 110 130 150 170 190<BR>
//! <BR>
//! GPU - A * x: 1330 2660 3990 5320 6650 7980 9310 10640 11970 13300<BR>
//! CPU - A * x: 1330 2660 3990 5320 6650 7980 9310 10640 11970 13300<BR>
//! GPU - A^H * x: 715 2145 3575 5005 6435 7865 9295 10725 12155 13585<BR>
//! CPU - A^H * x: 715 2145 3575 5005 6435 7865 9295 10725 12155 13585<BR>
//! </code>
//! 
//! @section plain_code Plain code
//! \code
//! #include "agile/gpu_environment.hpp"
//! #include "agile/gpu_vector.hpp"
//! #include "agile/gpu_matrix.hpp"
//! 
//! #include <iostream>
//! #include <iomanip>
//! 
//! #include "agile/cpu_vector.hpp"
//! #include "agile/cpu_matrix.hpp"
//! 
//! void output(const char* string, const std::vector<float>& x)
//! {
//!   std::cout << string;
//!   for (unsigned counter = 0; counter < x.size(); ++counter)
//!     std::cout << x[counter] << " ";
//!   std::cout << std::endl;
//! }
//! 
//! void output(const char* string, unsigned num_rows, unsigned num_columns,
//!             std::vector<float> data)
//! {
//!   std::vector<float>::iterator iter = data.begin();
//!   std::cout << string << std::endl;
//!   for (unsigned row = 0; row < num_rows; ++row)
//!   {
//!     std::cout << "  ";
//!     for (unsigned column = 0; column < num_columns; ++column)
//!       std::cout << std::setw(4) << *iter++;
//!     std::cout << std::endl;
//!   }
//!   std::cout << std::endl;
//! }
//! 
//! int main()
//! {
//!   agile::GPUEnvironment::allocateGPU(0);
//!   agile::GPUEnvironment::printInformation(std::cout);
//!   std::cout << std::endl;
//! 
//!   std::vector<float> x_host, y_host;
//!   for (unsigned counter = 0; counter < 10; ++counter)
//!   {
//!     x_host.push_back(counter * 2 + 1);
//!     y_host.push_back(counter * 2 + 2);
//!   }
//!   output("x: ", x_host);
//!   output("y: ", y_host);
//! 
//!   agile::GPUVector<float> x, y;
//!   x.assignFromHost(x_host.begin(), x_host.end());
//!   y.assignFromHost(y_host.begin(), y_host.end());
//! 
//!   agile::GPUVector<float> z(x.size());
//!   agile::addVector(x, y, z);
//! 
//!   std::vector<float> z_host;
//!   z.copyToHost(z_host);
//!   output("GPU - x + y: ", z_host);
//! 
//!   std::vector<float> z_reference(x_host.size());
//!   agile::addVector(x_host, y_host, z_reference);
//!   output("CPU - x + y: ", z_reference);
//! 
//!   std::cout << "GPU - (x, y) = " << agile::getScalarProduct(x, y)
//!             << std::endl;
//!   std::cout << "CPU - (x, y) = " << agile::getScalarProduct(x_host, y_host)
//!             << std::endl;
//! 
//!   std::vector<float> matrix_data;
//!   for (unsigned row = 0; row < x.size(); ++row)
//!     for (unsigned column = 0; column < x.size(); ++column)
//!       matrix_data.push_back(float(row + 1) * float(2 * column + 1));
//!   output("A: ", x.size(), x.size(), matrix_data);
//! 
//!   agile::GPUMatrix<float> A(x.size(), x.size(), &matrix_data[0]);
//!   agile::multiply(A, x, z);
//!   z.copyToHost(z_host);
//!   output("GPU - A * x: ", z_host);
//! 
//!   agile::CPUMatrix<float> A_host(x_host.size(), x_host.size(), &matrix_data[0]);
//!   agile::multiply(A_host, x_host, z_reference);
//!   output("CPU - A * x: ", z_reference);
//! 
//!   agile::multiply(x, A, z);
//!   z.copyToHost(z_host);
//!   output("GPU - A^H * x: ", z_host);
//!   agile::multiply(x_host, A_host, z_reference);
//!   output("CPU - A^H * x: ", z_reference);
//! 
//!   return 0;
//! }
//! 
//! \endcode
